## 背景

单机并发量和数据量有限，所以大部分网站都会使用多台服务器构成集群来对外提供服务；

节点多了，如何分配客户端请求——负载均衡

对于加权轮询算法（根据不同的硬件配置区别，引入权重值，将硬件配置更好的节点设置更高的权值），但是加权轮询算法的前提是建立在每个节点存储的数据相同的情况下，访问任意一个节点都可以得到结果。

加权轮询算法无法应对`分布式系统`，因为分布式系统中，每个节点存储的数据是不同的。（想要提高系统的容量，就会对数据进行水平切分到不同的节点中来存储，也就是将数据分布到不同的节点。比如**一个分布式 KV（key-value） 缓存系统，某个 key 应该到哪个或者哪些节点上获得，应该是确定的**，不是说任意访问一个节点都可以得到缓存结果的）

### 哈希算法

很容易想到，**哈希算法**。因为对同一个关键字进行哈希计算，每次计算都是相同的值，这样就可以将某个 key 确定到一个节点了，可以满足分布式系统的负载均衡需求。

哈希算法最简单的做法就是进行取模运算，比如分布式系统中有 3 个节点，基于 hash(key) % 3 公式对数据进行了映射。

如果客户端要获取指定 key 的数据，通过下面的公式可以定位节点：

但是有一个很致命的问题，**如果节点数量发生了变化，也就是在对系统做扩容或者缩容时，必须迁移改变了映射关系的数据**，否则会出现查询不到数据的问题。

[哈希算法的问题](https://developer.huawei.com/consumer/cn/forum/topic/0203810951415790238?fid=0101592429757310384)：扩缩节点时，最坏情况下所有的数据都需要迁移，数据迁移规模O(M) `M：总数据条数`

## 一致性hash算法

### 四个定义

一致性hash算法提出了在动态变化的Cache环境中，判定哈希算法好坏的四个定义:

1.`平衡性(Balance)`: 平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。很多哈希算法都能够满足这一条件。

2.`单调性(Monotonicity)`: 单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲加入到系统中。哈希的结果应能够保证原有已分配的内容可以被映射到原有的或者新的缓冲中去，而不会被映射到旧的缓冲集合中的其他缓冲区。

3.`分散性(Spread)`: 在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。当终端希望通过哈希过程将内容映射到缓冲上时，由于不同终端所见的缓冲范围有可能不同，从而导致哈希的结果不一致，最终的结果是相同的内容被不同的终端映射到不同的缓冲区中。这种情况显然是应该避免的，因为它导致相同内容被存储到不同缓冲中去，降低了系统存储的效率。分散性的定义就是上述情况发生的严重程度。好的哈希算法应能够尽量避免不一致的情况发生，也就是尽量降低分散性。

4.`负载(Load)`: 负载问题实际上是从另一个角度看待分散性问题。既然不同的终端可能将相同的内容映射到不同的缓冲区中，那么对于一个特定的缓冲区而言，也可能被不同的用户映射为不同 的内容。与分散性一样，这种情况也是应当避免的，因此好的哈希算法应能够尽量降低缓冲的负荷。

### 一致性哈希概念

一致性哈希算法就很好地解决了分布式系统在扩容或者缩容时，发生过多的数据迁移的问题。

一致哈希算法也用了取模运算，但与哈希算法不同的是，哈希算法是对节点的数量进行取模运算，而**一致哈希算法是对 2^32 进行取模运算，是一个固定的值**。

>为什么是2^32个桶空间？
>
>桶空间的大小根据选用的hash算法来定, 一般情况下, hash的返回结果为32位的整型数据, 无符号的整型的最大值是2^32-1, 最小值是0, 一共2^32个数字, 所有, 桶空间也就是2^32个了;

我们可以把一致哈希算法是对 2^32 进行取模运算的结果值组织成一个圆环，就像钟表一样，钟表的圆可以理解成由 60 个点组成的圆，而此处我们把这个圆想象成由 2^32 个点组成的圆，这个圆环被称为**哈希环**

![cke_134.png](https://gitee.com/zhang-songyao/blog-images/raw/master/202211212012246.png)

一致性哈希需要两步哈希：

- 第一步：对存储节点进行哈希计算，也就是对存储节点做哈希映射，比如根据节点的 IP 地址进行哈希；
- 第二步：当对数据进行存储或访问时，对数据进行哈希映射；

对要查询的 key-01 进行哈希计算，确定此 key-01 映射在哈希环的位置，然后从这个位置往顺时针的方向找到第一个节点，就是存储该 key-01 数据的节点。

![cke_136.png](https://gitee.com/zhang-songyao/blog-images/raw/master/202211212013222.png)

**一致性哈希是指将「存储节点」和「数据」都映射到一个首尾相连的哈希环上**。

所以，当需要对指定 key 的值进行读写的时候，要通过下面 2 步进行寻址：

- 首先，对 key 进行哈希计算，确定此 key 在环上的位置；
- 然后，从这个位置沿着顺时针方向走，遇到的第一节点就是存储 key 的节点。

通过一致性哈希可以解决增加或者减少一个节点发生的大量数据迁移操作：

假设节点数量从 3 增加到了 4，新的节点 D 经过哈希计算后映射到了下图中的位置：

![cke_137.png](https://gitee.com/zhang-songyao/blog-images/raw/master/202211212021386.png)

key-01、key-03 都不受影响，只有 key-02 需要被迁移节点 D。

假设节点数量从 3 减少到了 2，比如将节点 A 移除：

![cke_138.png](https://gitee.com/zhang-songyao/blog-images/raw/master/202211212021909.png)

key-02 和 key-03 不会受到影响，只有 key-01 需要被迁移节点 B。

因此，**在一致哈希算法中，如果增加或者移除一个节点，仅影响该节点在哈希环上顺时针相邻的后继节点，其它数据也不会受到影响**。

### 节点分配不均匀

一致性哈希虽然减少了数据迁移量，但是当节点分配不均匀时，会出现多个客户端访问到一个节点，导致负载不均衡，出现雪崩式连锁反应，如图：

![cke_139.png](https://gitee.com/zhang-songyao/blog-images/raw/master/202211212017786.png)



这时候有一半以上的数据的寻址都会找节点 A，也就是访问请求主要集中的节点 A 上，这种情况一点都不均衡。

另外，在这种节点分布不均匀的情况下，进行容灾与扩容时，哈希环上的相邻节点容易受到过大影响，容易发生雪崩式的连锁反应。

比如，上图中如果节点 A 被移除了，当节点 A 宕机后，根据一致性哈希算法的规则，其上数据应该全部迁移到相邻的节点 B 上，这样，节点 B 的数据量、访问量都会迅速增加很多倍，一旦新增的压力超过了节点 B 的处理能力上限，就会导致节点 B 崩溃，进而形成雪崩式的连锁反应。

所以，**一致性哈希算法虽然减少了数据迁移量，但是存在节点分布不均匀的问题**。

### [虚拟节点](https://researchlab.github.io/2017/01/16/consistent-hashing-summary/)

想要解决节点在哈希环上分布不均匀的问题，就是需要大量的节点，节点越多，哈希环上节点分布越均匀。但是实际生产环境没有这么多的节点，所以引入了虚拟节点的概念，也就是对一个真实节点做多个副本。

考察哈希算法的另一个指标：`平衡性`

**平衡性** 是指哈希的结果能够尽可能分布到所有的缓冲中去

如上情况，一个节点宕机后会引起下个节点的存储及流量压力变大，这一点违背了平衡性，节点宕机后，流量及内存的分配方式打破了原有的平衡

虚拟节点，从名字可以看出来，这个节点是个虚拟的，每个实际节点对应多个虚拟节点。比较专业的说法如下：

“虚拟节点”（ virtual node ）是实际节点（机器）在 hash 空间的复制品（ replica ），一实际个节点（机器）对应了若干个“虚拟节点”，这个对应个数也成为“复制个数”，“虚拟节点”在 hash 空间中以hash值排列。

举例：

Visual100—> Real1

Visual101—> Real1

Visual200—> Real2

Visual201—> Real2

Visual300—> Real3

Visual301—> Real3

同样的，hash之后的结果如下：

hash(Visual100)—> V100 —> Real1

hash(Visual101)—> V101 —> Real1

hash(Visual200)—> V200 —> Real2

hash(Visual201)—> V201 —> Real2

hash(Visual300)—> V300 —> Real3

hash(Visual301)—> V301 —> Real3

![虚拟节点](https://gitee.com/zhang-songyao/blog-images/raw/master/202211212026756.jpg)

可以看到，节点数量多了后，节点在哈希环上的分布就相对均匀了。这时候，如果有访问请求寻址到某个虚拟节点，接着再通过虚拟节点找到真实节点，这样就可以请求到真实的服务器了。

> 在实际的工程中，虚拟节点的数量会大很多，比如 Nginx 的一致性哈希算法，每个权重为 1 的真实节点就含有160 个虚拟节点。

假设Real1机器宕机，则会发生一下情况。

1、原先存储在虚拟节点V100上的k1数据将迁移到V301上，也就意味着迁移到了Real3机器上。

2、原先存储再虚拟节点V101上的k4数据将迁移到V200上，也就意味着迁移到了Real2机器上。

结果如下图：

![虚拟节点](https://gitee.com/zhang-songyao/blog-images/raw/master/202211212029013.png)

某个节点宕机，存储及流量压力并没有全部转移到某台机器上，而是分散到了多台节点上。解决了节点宕机存在的雪崩问题

### [算法实现](https://researchlab.github.io/2017/01/16/consistent-hashing-summary/)